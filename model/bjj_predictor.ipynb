{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import kerastuner as kt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bjj.npz file\n",
    "path = os.path.join(os.getcwd(), 'bjj.npz')\n",
    "with np.load(path) as data:\n",
    "    train_examples = data['train_examples']\n",
    "    train_labels = data['train_labels']\n",
    "    test_examples = data['test_examples']\n",
    "    test_labels = data['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test examples to find max for normalization\n",
    "examples_maxes = np.max(np.concatenate((train_examples, test_examples)), axis=0)\n",
    "\n",
    "# Normalize train and test examples to values in [0, 1]\n",
    "train_examples = train_examples.astype('float32') / examples_maxes\n",
    "test_examples = test_examples.astype('float32') / examples_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save example maxes\n",
    "np.savez('examples_maxes.npz', examples_maxes=examples_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model builder for Keras Tuner\n",
    "def model_builder(hp):\n",
    "    # Sequential with 12 input nodes\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = (12,)))\n",
    "    \n",
    "    # Tune number of units in first Dense layer\n",
    "    hp_units_1 = hp.Int('units_1', min_value = 32, max_value = 512, step = 32)\n",
    "    hp_reg_1 = hp.Choice('reg_1', values = [1e-0, 1e-1, 1e-2, 1e-3, 1e-4])\n",
    "    model.add(keras.layers.Dense(units = hp_units_1, activation = 'relu', kernel_regularizer=keras.regularizers.l2(hp_reg_1)))\n",
    "    \n",
    "    # Tune dropout rate in Dropout layer\n",
    "    hp_dropout_rate = hp.Choice('dropout_rate', values = [0.00, 0.25, 0.50, 0.75])\n",
    "    model.add(keras.layers.Dropout(hp_dropout_rate))\n",
    "    \n",
    "    # Tune number of units in second Dense layer\n",
    "    hp_units_2 = hp.Int('units_2', min_value = 32, max_value = 512, step = 32)\n",
    "    hp_reg_2 = hp.Choice('reg_2', values = [1e-0, 1e-1, 1e-2, 1e-3, 1e-4])\n",
    "    model.add(keras.layers.Dense(units = hp_units_2, activation = 'relu', kernel_regularizer=keras.regularizers.l2(hp_reg_2)))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(5))\n",
    "    \n",
    "    # Tune learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                  loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Keras Tuner\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy',\n",
    "                     max_epochs = 10,\n",
    "                     factor = 3,\n",
    "                     directory = '.',\n",
    "                     project_name = 'bjj_kt',\n",
    "                     overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the training output at the end of every training\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best hyperparameters\n",
    "tuner.search(train_examples, train_labels, epochs = 10, validation_data = (test_examples, test_labels), callbacks = [ClearTrainingOutput()])\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# Output hyperparameter search results\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "The optimal number of units in the first densely-connected layer is {best_hps.get('units_1')}. \n",
    "The optimal l2 regulariation in the first densely-connected layer is {best_hps.get('reg_1')}. \n",
    "The optimal dropout rate in the dropout layer is {best_hps.get('dropout_rate')}. \n",
    "The optimal number of units in the second densely-connected layer is {best_hps.get('units_2')}. \n",
    "The optimal l2 regulariation in the second densely-connected layer is {best_hps.get('reg_2')}. \n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the model using the found hyperparameters\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_examples, train_labels, epochs = 10, validation_data = (test_examples, test_labels), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_acc = model.evaluate(test_examples, test_labels, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Softmax layer to turn the model into a probability model\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for all test examples\n",
    "predictions = probability_model.predict(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on one example only\n",
    "predictions_single = probability_model.predict(np.expand_dims(test_examples[1], 0))\n",
    "\n",
    "print(predictions_single)\n",
    "print(np.argmax(predictions_single[0]))\n",
    "print(test_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in h5 format\n",
    "model.save('bjj_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reloading the model and outputing the summary\n",
    "new_model = tf.keras.models.load_model('bjj_model.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluate on the loaded model\n",
    "loss, acc = new_model.evaluate(test_examples, test_labels, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the loaded model to a probability model\n",
    "new_probability_model = tf.keras.Sequential([new_model, tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test probability model on one test example only\n",
    "predictions_single = new_probability_model.predict(np.expand_dims(test_examples[1], 0))\n",
    "\n",
    "print(predictions_single)\n",
    "print(np.argmax(predictions_single[0]))\n",
    "print(test_labels[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
